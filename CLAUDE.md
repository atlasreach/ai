# AI Model Studio - Project Overview

## ğŸš¨ CURRENT STATUS (Oct 29, 2025 - 4:45 PM EST)

**Model**: SAR (Source 1 only - 7 images)
**Phase**: Phase 2 - LoRA Training Setup
**Location**: RunPod terminal at `/workspace`

### âœ… Completed Today:
1. âœ… Generated captions for all SAR enhanced images using BLIP
2. âœ… Uploaded 7 enhanced images + captions to S3: `s3://destinty-workflow-1761724503/results/nsfw/source_1/enhanced/`
3. âœ… Created `runpod_train_sar_source1_only.sh` script for automated training
4. âœ… Fixed SimpleTuner installation bug (was using `requirements.txt`, now uses `pip install simpletuner[cuda]`)
5. âœ… Committed fix to GitHub (commit: `16ef9dd`)
6. âœ… Pulled updated script to RunPod
7. âœ… Downloaded training data from S3 to `/workspace/lora_training/10_sar/`

### ğŸ”„ IN PROGRESS RIGHT NOW:
**SimpleTuner is installing** (process 6823, running 15+ seconds, using 10.6% CPU)
- Command: `pip install -q simpletuner[cuda]`
- Expected time: 10-15 minutes
- Status: âœ… Working correctly (verified with `ps aux | grep pip`)

### â­ï¸ NEXT STEPS (When you come back online):

1. **Check if SimpleTuner finished installing:**
   ```bash
   # In RunPod terminal, check if still running:
   ps aux | grep pip

   # If nothing shows, it's done! You should see:
   # "âœ“ SimpleTuner installed"
   # "Step 3: Creating training config..."
   ```

2. **If installation completed, training should auto-start:**
   ```bash
   # The script will create:
   # - /workspace/train_config.json
   # - /workspace/train_sar_flux.sh
   # - Then run: bash /workspace/train_sar_flux.sh
   ```

3. **Monitor training progress:**
   ```bash
   # Training takes ~30-60 minutes
   # Watch for: "Training Complete!"
   # Output will be in: /workspace/sar_lora_output/
   ```

4. **If installation failed or stuck:**
   ```bash
   # Kill and restart:
   pkill -9 pip
   cd /workspace
   pip install simpletuner[cuda]  # Without -q to see progress

   # Then run:
   bash /workspace/ai/runpod_train_sar_source1_only.sh
   ```

### ğŸ› Known Issues & Fixes:
- âŒ **SimpleTuner git clone + requirements.txt** â†’ âœ… Fixed: Now uses `pip install simpletuner[cuda]`
- â³ **Installation seems frozen** â†’ Normal! Takes 10-15 min, use `ps aux | grep pip` to verify

### ğŸ“ Important File Locations:

**In RunPod (`/workspace`):**
- Training images: `/workspace/lora_training/10_sar/` (7 images + 7 captions)
- Setup script: `/workspace/ai/runpod_train_sar_source1_only.sh`
- Training script: `/workspace/train_sar_flux.sh` (created by setup)
- Output: `/workspace/sar_lora_output/` (will contain trained LoRA)

**In GitHub Codespaces (`/workspaces/ai`):**
- Main script: `runpod_train_sar_source1_only.sh`
- Master workflow: `master_v2.py`
- Caption scripts: `generate_captions.py`, `caption_one_folder.py`

**In S3 (`destinty-workflow-1761724503`):**
- Images: `results/nsfw/source_1/enhanced/sar-s1-t*.jpg`
- Captions: `results/nsfw/source_1/enhanced/sar-s1-t*.txt`

---

## ğŸ¯ PROJECT VISION

Build a **professional SaaS platform** for creating personalized AI models through face swapping, enhancement, and LoRA training. Think "MaxStudio meets Stable Diffusion" - a complete pipeline from photos to trained models.

---

## ğŸ“‹ DEVELOPMENT PHASES

### **PHASE 1: Core Workflow & Multi-Model System** â³ IN PROGRESS

**Goal**: Production-ready CLI tool for managing multiple AI models with face swap + enhancement

**Features**:
- âœ… Multi-model support (organize by person: andie, blondie, etc.)
- âœ… Multiple source photos per model
- âœ… NSFW/SFW content separation
- âœ… MaxStudio API integration (face swap + enhance)
- âœ… AWS S3 storage with smart organization
- âœ… Progress tracking + resume capability
- âœ… Cost tracking per model
- âœ… Quality validation (face detection, size checks)
- âœ… Smart file naming: `{model}-s{source#}-t{target#}-{type}-{stage}.jpg`
- âœ… Error handling + automatic retry
- âœ… Configuration per model

**Tech Stack**:
- Python 3.12
- MaxStudio API (face swap, enhancement)
- AWS S3 (boto3)
- OpenCV (face detection)

**Structure**:
```
ai/
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ andie/
â”‚   â”‚   â”œâ”€â”€ source/              # Source face photos
â”‚   â”‚   â”œâ”€â”€ targets/nsfw/        # Target bodies (NSFW)
â”‚   â”‚   â”œâ”€â”€ targets/sfw/         # Target bodies (SFW)
â”‚   â”‚   â”œâ”€â”€ results/
â”‚   â”‚   â”‚   â”œâ”€â”€ nsfw/
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ source_1/    # Results from source 1
â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ swapped/
â”‚   â”‚   â”‚   â”‚   â”‚   â””â”€â”€ enhanced/
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ source_2/
â”‚   â”‚   â”‚   â””â”€â”€ sfw/
â”‚   â”‚   â”œâ”€â”€ config.json          # Model settings
â”‚   â”‚   â”œâ”€â”€ progress.json        # Processing state
â”‚   â”‚   â””â”€â”€ costs.json           # Credit tracking
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ master.py                # Main CLI tool
â”‚   â””â”€â”€ lib/                     # Helper modules
â”œâ”€â”€ models.json                  # Global model registry
â””â”€â”€ .env                         # API keys
```

**CLI Interface**:
```bash
python master.py

AI Model Studio
===============
[1] Create New Model
[2] Work with Existing Model
[3] View All Models
[4] Exit

â†’ You select: 1

Enter model name: andie
âœ“ Model created: models/andie/

Upload source photos (comma-separated paths or drag folder):
â†’ /path/to/face1.jpg, /path/to/face2.jpg

âœ“ Validated: 2 photos
âœ“ Renamed: face1.jpg â†’ andie-source-1.jpg
âœ“ Renamed: face2.jpg â†’ andie-source-2.jpg

Which folder to process?
[1] NSFW
[2] SFW
[3] Both

â†’ You select: 1

Upload target photos to models/andie/targets/nsfw/:
â†’ [Paste folder path or files]

âœ“ 5 targets uploaded
âœ“ Face detected in 5/5 targets

Estimated cost: 120 credits (10 swaps Ã— 10, 10 enhance Ã— 2)
Continue? [Y/n]

Processing:
  [â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘] 80% | andie-s2-t004-nsfw-enhanced.jpg

âœ“ Complete! 10/10 successful
âœ“ Saved to: models/andie/results/nsfw/
âœ“ Uploaded to S3: andie-workflow-1730249876
âœ“ Cost: 118 credits

Process SFW folder too? [Y/n]
```

---

### **PHASE 2: Caption Generation & LoRA Training** ğŸ”œ PLANNED

**Goal**: Automatically generate captions for images and train LoRA models for Stable Diffusion

**Features**:
- ğŸ”œ Image captioning using BLIP/CLIP models
- ğŸ”œ Generate training captions: `"a photo of {trigger_word}, {description}"`
- ğŸ”œ LoRA training pipeline (Stable Diffusion)
- ğŸ”œ Automated dataset preparation
- ğŸ”œ Model versioning & comparison
- ğŸ”œ Quality scoring for training images

**Tech Stack** (TBD):
- BLIP-2 or CLIP Interrogator (captioning)
- Kohya_ss or SimpleTuner (LoRA training)
- Stable Diffusion WebUI (testing)
- Possible: Hugging Face Diffusers

**Workflow**:
```
Enhanced Images
    â†“
BLIP/CLIP Caption Generation
    â†“
Manual Caption Review/Edit
    â†“
Dataset Preparation (pairs: image + text)
    â†“
LoRA Training (Kohya/SimpleTuner)
    â†“
Model Testing & Comparison
    â†“
Export Final LoRA
```

**Example Captions**:
```
andie-s1-t001-nsfw-enhanced.jpg
â†’ "a photo of andie, woman, full body, studio lighting, professional photography"

andie-s1-t002-sfw-enhanced.jpg
â†’ "a photo of andie, woman, portrait, outdoor, natural lighting, smiling"
```

---

### **PHASE 3: REST API & Background Jobs** ğŸ”® FUTURE

**Goal**: Expose workflow via REST API with async processing

**Features**:
- FastAPI server with auto-generated docs
- WebSocket for live progress updates
- Background job queue (Celery/RQ)
- Multi-user support
- Authentication & API keys
- S3 presigned URLs for downloads

---

### **PHASE 4: React Web UI** ğŸ”® FUTURE

**Goal**: Professional SaaS interface for managing models

**Features**:
- React 18 + Tailwind CSS
- Dashboard with model cards
- Before/after image comparison slider
- Drag & drop file uploads
- Live progress tracking
- Cost calculator
- Export & download

---

## ğŸ”‘ CURRENT STACK (Phase 1)

| Component | Technology | Purpose |
|-----------|-----------|---------|
| Language | Python 3.12 | Core logic |
| Face Swap | MaxStudio API | Face replacement |
| Enhancement | MaxStudio API | Image upscaling (2x) |
| Storage | AWS S3 (boto3) | Cloud storage |
| Face Detection | OpenCV + Haar Cascade | Quality validation |
| Config | JSON files | Model settings |
| CLI | Python input() | User interaction |

---

## ğŸ“Š CURRENT PROGRESS

### âœ… Completed (Phase 0 - Prototype)
- [x] Basic face swap script (single image)
- [x] Enhancement script
- [x] S3 upload with presigned URLs
- [x] Quality checking (BRISQUE + CLIP-IQA)
- [x] Successfully processed 5 NSFW images for "andie" model
- [x] Validated MaxStudio API integration
- [x] Cost: ~118 credits for 10 images (5 swap + 5 enhance)

### ğŸ—ï¸ In Progress (Phase 1)
- [ ] Restructure into `models/` directory
- [ ] Create `master.py` CLI tool
- [ ] Multi-model support
- [ ] Progress tracking + resume
- [ ] Cost tracking per model
- [ ] Smart file naming
- [ ] Configuration system
- [ ] Error handling + retry logic

---

## ğŸ’° COST ANALYSIS

Based on MaxStudio API pricing:

| Operation | Credits/Image | 10 Images | 100 Images |
|-----------|---------------|-----------|------------|
| Face Swap | ~10 | 100 | 1,000 |
| Enhance (2x) | ~2 | 20 | 200 |
| **Total** | **~12** | **120** | **1,200** |

**For LoRA Training**: Recommended 20-50 high-quality images per model
- Cost: 240-600 credits per model
- Processing time: ~5-10 minutes

---

## ğŸ¯ SUCCESS METRICS

**Phase 1 Goals**:
1. âœ… Process 10+ images in one run without errors
2. âœ… Resume if interrupted
3. âœ… Track costs accurately
4. âœ… Validate quality automatically (reject bad images)
5. âœ… Smart organization (easy to find results)

**Phase 2 Goals**:
1. Generate accurate captions for 90%+ of images
2. Successfully train LoRA model
3. Generate consistent outputs using trained model
4. Model file < 100MB

---

## ğŸš€ QUICK START (Phase 1)

Once master.py is complete:

```bash
# Install dependencies
pip install boto3 python-dotenv requests opencv-python-headless

# Set up environment
cp .env.example .env
# Edit .env with your API keys

# Run CLI tool
python master.py
```

---

## ğŸ“ NOTES

### MaxStudio API Learnings
- âœ… Use `/swap-image` endpoint (not `/faceswap`)
- âœ… Response uses `detectedFaces` key
- âœ… Payload format: `newFace: url` (not nested object)
- âœ… Use regional S3 URLs (not generic amazonaws.com)
- âœ… Presigned URLs work (7-day expiry recommended)
- âœ… Enhancement improves quality significantly (+29% beauty score avg)

### File Naming Convention
```
{model}-s{source#}-t{target#}-{type}-{stage}.jpg

Examples:
- andie-s1-t001-nsfw-swapped.jpg
- andie-s2-t003-sfw-enhanced.jpg
- blondie-s1-t010-nsfw-enhanced.jpg
```

### Quality Thresholds
- Face detection: Must detect at least 1 face
- File size: < 5MB (API limit)
- Resolution: Minimum 800px on shortest side
- CLIP Beauty Score: > 0.6 for training (enhanced images)

---

## ğŸ¤ CONTRIBUTING

This is currently a solo project but built with production standards for potential future contributors.

---

**Last Updated**: October 29, 2025
**Current Phase**: Phase 1 - Core Workflow
**Status**: ğŸ—ï¸ Building CLI tool with multi-model support
